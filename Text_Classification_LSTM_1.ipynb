{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc60456-c076-4512-b8da-4a427c022b0a",
   "metadata": {},
   "source": [
    "# Import Packages and Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862b6243-821f-4e9d-8e47-ba38073f04ef",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6311d0b2-3e6b-4e4c-bc69-769a3763c644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score,hamming_loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399c2cb2-24f7-433a-9dc3-fa6696111362",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "806cd406-6a1c-4630-a5ca-71a0e71e25f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_after_cleansing_normalized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27fd0b7d-709d-4bb9-8804-32022b827c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>HS</th>\n",
       "      <th>normalized_tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- disaat semua cowok berusaha melacak perhatia...</td>\n",
       "      <td>1</td>\n",
       "      <td>- di saat semua pria berusaha melacak perhatia...</td>\n",
       "      <td>di saat semua pria berusaha melacak perhatian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT USER: USER siapa yang telat ngasih tau elu?...</td>\n",
       "      <td>0</td>\n",
       "      <td>RT USER: USER siapa  telat memberi tau elu?eda...</td>\n",
       "      <td>rt user user siapa telat memberi tau eluedan s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41. Kadang aku berfikir, kenapa aku tetap perc...</td>\n",
       "      <td>0</td>\n",
       "      <td>41. Kadang aku berfikir, kenapa aku tetap perc...</td>\n",
       "      <td>kadang aku berfikir kenapa aku tetap percaya ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USER USER AKU ITU AKU\\n\\nKU TAU MATAMU SIPIT T...</td>\n",
       "      <td>0</td>\n",
       "      <td>USER USER AKU ITU AKU\\n\\nKU TAU MATAMU SIPIT T...</td>\n",
       "      <td>user user aku itu akunnku tau matamu sipit tap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USER USER Kaum cebong kapir udah keliatan dong...</td>\n",
       "      <td>1</td>\n",
       "      <td>USER USER Kaum kecebong kafir sudah kelihatan ...</td>\n",
       "      <td>user user kaum kecebong kafir sudah kelihatan ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  HS  \\\n",
       "0  - disaat semua cowok berusaha melacak perhatia...   1   \n",
       "1  RT USER: USER siapa yang telat ngasih tau elu?...   0   \n",
       "2  41. Kadang aku berfikir, kenapa aku tetap perc...   0   \n",
       "3  USER USER AKU ITU AKU\\n\\nKU TAU MATAMU SIPIT T...   0   \n",
       "4  USER USER Kaum cebong kapir udah keliatan dong...   1   \n",
       "\n",
       "                                    normalized_tweet  \\\n",
       "0  - di saat semua pria berusaha melacak perhatia...   \n",
       "1  RT USER: USER siapa  telat memberi tau elu?eda...   \n",
       "2  41. Kadang aku berfikir, kenapa aku tetap perc...   \n",
       "3  USER USER AKU ITU AKU\\n\\nKU TAU MATAMU SIPIT T...   \n",
       "4  USER USER Kaum kecebong kafir sudah kelihatan ...   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0   di saat semua pria berusaha melacak perhatian...  \n",
       "1  rt user user siapa telat memberi tau eluedan s...  \n",
       "2   kadang aku berfikir kenapa aku tetap percaya ...  \n",
       "3  user user aku itu akunnku tau matamu sipit tap...  \n",
       "4  user user kaum kecebong kafir sudah kelihatan ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75671f75-af3f-4161-987f-135a808238f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18396, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b499227-f530-4ba0-8f77-2353b01283de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HS\n",
       "0    10947\n",
       "1     7449\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['HS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82e71c9c-52c5-49d0-bfeb-26ee12b01447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, log_loss\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b812711-b3f7-4e4e-89aa-b54bf87a49ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df=df['clean_tweet']\n",
    "output_df=df['HS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13f6180f-e716-4b27-b6ef-06139a4be254",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(input_df, output_df, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a263258-4917-4b56-b5e2-e02884b9e96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3680,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bef6874-feac-4852-b9a9-3b3ad92f9ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14716,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71fe9046-e01b-4578-946e-97a2bfedca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4febcd4e-bda1-4d46-be24-03b14e1e9a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1472,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9668c15-1be8-4369-a789-76f875470919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3927     katauntukhariini ahoker goblok tuntut lengserk...\n",
       "7130     user user user egp kalau individualnya kiraan ...\n",
       "17884    shameonyoumalaysia shameofyoumalaysia anything...\n",
       "15132    we must disband those are threatening our home...\n",
       "15415    the place is a warehouse that has been filled ...\n",
       "Name: clean_tweet, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d292aca1-3b4b-4c2a-9a23-e8e72973047b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3927     1\n",
       "7130     0\n",
       "17884    1\n",
       "15132    1\n",
       "15415    0\n",
       "Name: HS, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8bdc51-4d2e-48cb-85ff-ff5b2e7f0ece",
   "metadata": {},
   "source": [
    "# Size of Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18f68ee2-140b-4ab0-8184-f812f64fa8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd3c864d-3b93-4bf9-8e3b-8b764c56dc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "vect = Tokenizer(num_words = vocab_size)\n",
    "vect.fit_on_texts(x_train)\n",
    "# vocab_size = len(vect.word_index)+1\n",
    "\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e973a979-e30a-40a0-a607-de70e5228be6",
   "metadata": {},
   "source": [
    "# Modelling Using LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b72606f-f106-4280-9f3d-42cc89985d21",
   "metadata": {},
   "source": [
    "## Padding and preparing input sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "244fcf5e-8a87-467f-b427-0c6cac2f770f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2798  160  226 ...    0    0    0]\n",
      " [   1    1    1 ...    0    0    0]\n",
      " [  58 4358  650 ...    0    0    0]\n",
      " ...\n",
      " [   9  366   15 ...    0    0    0]\n",
      " [2340  652 1058 ...    0    0    0]\n",
      " [ 281  861  314 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "encoded_docs_train = vect.texts_to_sequences(x_train)\n",
    "padded_docs_train = sequence.pad_sequences(encoded_docs_train,maxlen=100,padding='post')\n",
    "print(padded_docs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cf25d5e-c0c9-4615-9772-8300c01e15b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  25    1 2683 ...    0    0    0]\n",
      " [   1    1   54 ...    0    0    0]\n",
      " [3991  223 1343 ...    0    0    0]\n",
      " ...\n",
      " [   1   91  153 ...    0    0    0]\n",
      " [   1    1  157 ...    0    0    0]\n",
      " [ 439  399   17 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "encoded_docs_test = vect.texts_to_sequences(x_test)\n",
    "padded_docs_test = sequence.pad_sequences(encoded_docs_test,maxlen=100,padding='post')\n",
    "print(padded_docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55051cb5-8f20-4dcb-b116-04e581263bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  26   82    0 ...    0    0    0]\n",
      " [1414   21 2701 ...    0    0    0]\n",
      " [ 738  131 2565 ...    0    0    0]\n",
      " ...\n",
      " [   1   67   46 ...    0    0    0]\n",
      " [   1 1318  678 ...    0    0    0]\n",
      " [   1    1   53 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "encoded_docs_val = vect.texts_to_sequences(x_val)\n",
    "padded_docs_val = sequence.pad_sequences(encoded_docs_val,maxlen=100,padding='post')\n",
    "print(padded_docs_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077d2c95-7fef-4222-9e33-ebd6c3c8487d",
   "metadata": {},
   "source": [
    "## Defining Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ef3a40-7c24-437f-afaf-08a20de8af11",
   "metadata": {},
   "source": [
    "**Penjelasan:**\n",
    "- vocab_size adalah ukuran kosakata (jumlah kata yang berbeda dalam korpus teks)\n",
    "- output_dim adalah dimensi dari vektor ruang kata yang dihasilkan. Dalam kasus ini, dimensi vektor adalah 64.\n",
    "- Lapisan LSTM dalam kode ini memiliki 64 unit LSTM. Bidirectional menandakan bahwa LSTM ini akan dipelajari baik dari data masa lalu ke masa depan maupun sebaliknya, meningkatkan kapabilitasnya dalam memahami konteks dalam urutan.\n",
    "- Menambahkan lapisan Dense (fully connected) dengan 64 unit dan fungsi aktivasi ReLU (Rectified Linear Activation). Lapisan Dense ini berfungsi sebagai lapisan tersembunyi, yang bertanggung jawab untuk mempelajari representasi fitur yang lebih tingkat dari data.\n",
    "- fungsi aktivasi sigmoid digunakan untuk menghasilkan probabilitas untuk masing-masing kelas (dsini terdapat 1 kelas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5e4f267-336b-4ae7-878e-4ffb27fa1e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              66048     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 394,369\n",
      "Trainable params: 394,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# # Inisialisasi model\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(vocab_size, output_dim=64))\n",
    "# model.add(Bidirectional(LSTM(64)))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "# model.add(Input((5000,)))\n",
    "model.add(Embedding(vocab_size, output_dim=64))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d5cae34-7b5d-4517-8a42-8383ecc8501d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79504ed5-eeb8-425e-aed2-40272edc8e96",
   "metadata": {},
   "source": [
    "## Training using adam optimizer and binary cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "525ca5ba-bdf2-4050-a0bc-bd3e5055e51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "52/52 - 21s - loss: 0.6322 - accuracy: 0.6323 - val_loss: 0.5080 - val_accuracy: 0.7588 - 21s/epoch - 399ms/step\n",
      "Epoch 2/15\n",
      "52/52 - 21s - loss: 0.4115 - accuracy: 0.8139 - val_loss: 0.4236 - val_accuracy: 0.8077 - 21s/epoch - 405ms/step\n",
      "Epoch 3/15\n",
      "52/52 - 22s - loss: 0.3101 - accuracy: 0.8680 - val_loss: 0.4494 - val_accuracy: 0.8125 - 22s/epoch - 422ms/step\n",
      "Epoch 4/15\n",
      "52/52 - 22s - loss: 0.2655 - accuracy: 0.8894 - val_loss: 0.4681 - val_accuracy: 0.8003 - 22s/epoch - 416ms/step\n",
      "Epoch 5/15\n",
      "52/52 - 22s - loss: 0.2244 - accuracy: 0.9126 - val_loss: 0.5425 - val_accuracy: 0.7948 - 22s/epoch - 417ms/step\n",
      "Epoch 6/15\n",
      "52/52 - 23s - loss: 0.1975 - accuracy: 0.9207 - val_loss: 0.5853 - val_accuracy: 0.7942 - 23s/epoch - 434ms/step\n",
      "Epoch 7/15\n",
      "52/52 - 22s - loss: 0.1641 - accuracy: 0.9385 - val_loss: 0.6596 - val_accuracy: 0.7846 - 22s/epoch - 429ms/step\n",
      "Epoch 8/15\n",
      "52/52 - 22s - loss: 0.1355 - accuracy: 0.9524 - val_loss: 0.7948 - val_accuracy: 0.7819 - 22s/epoch - 430ms/step\n",
      "Epoch 9/15\n",
      "52/52 - 22s - loss: 0.1144 - accuracy: 0.9597 - val_loss: 0.8104 - val_accuracy: 0.7792 - 22s/epoch - 427ms/step\n",
      "Epoch 10/15\n",
      "52/52 - 23s - loss: 0.1031 - accuracy: 0.9646 - val_loss: 0.8335 - val_accuracy: 0.7738 - 23s/epoch - 434ms/step\n",
      "Epoch 11/15\n",
      "52/52 - 22s - loss: 0.0918 - accuracy: 0.9693 - val_loss: 0.9648 - val_accuracy: 0.7609 - 22s/epoch - 430ms/step\n",
      "Epoch 12/15\n",
      "52/52 - 22s - loss: 0.0828 - accuracy: 0.9730 - val_loss: 1.0048 - val_accuracy: 0.7751 - 22s/epoch - 424ms/step\n",
      "Epoch 13/15\n",
      "52/52 - 22s - loss: 0.0701 - accuracy: 0.9779 - val_loss: 1.1658 - val_accuracy: 0.7772 - 22s/epoch - 431ms/step\n",
      "Epoch 14/15\n",
      "52/52 - 23s - loss: 0.0612 - accuracy: 0.9798 - val_loss: 1.0934 - val_accuracy: 0.7575 - 23s/epoch - 435ms/step\n",
      "Epoch 15/15\n",
      "52/52 - 23s - loss: 0.0603 - accuracy: 0.9809 - val_loss: 1.2409 - val_accuracy: 0.7738 - 23s/epoch - 435ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(padded_docs_train, y_train.values, \n",
    "                    validation_data=(padded_docs_val, y_val.values),\n",
    "                    epochs=15, batch_size=256, \n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1c1f699-76c5-4b5e-946a-ded596a18c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 2s 14ms/step - loss: 1.1906 - accuracy: 0.7761\n",
      "Accuracy: 77.61%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(padded_docs_test, y_test.values)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5023d0d-4e1e-4eaf-a087-7075a82d6897",
   "metadata": {},
   "source": [
    "# Predict and Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92147bbc-640d-49ef-9a7e-cb568370fc63",
   "metadata": {},
   "source": [
    "## Predict Data Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b63f0e36-a71a-4267-8a09-98c1c4ba0d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 2s 14ms/step\n",
      "414/414 [==============================] - 6s 13ms/step\n",
      "46/46 [==============================] - 1s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(padded_docs_test)\n",
    "predict_train = model.predict(padded_docs_train)\n",
    "predict_val = model.predict(padded_docs_val)\n",
    "thresholds=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67bcfc44-19ac-446a-9227-23da7f585b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelSetAccuracy(y_true, y_pred):\n",
    "    acc_list = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        set_true = set( np.where(y_true[i])[0] )\n",
    "        set_pred = set( np.where(y_pred[i])[0] )\n",
    "#         print('\\nset_true: {0}'.format(set_true))\n",
    "#         print('set_pred: {0}'.format(set_pred))\n",
    "        tmp_a = None\n",
    "        if len(set_true) == 0 and len(set_pred) == 0:\n",
    "            tmp_a = 1\n",
    "        else:\n",
    "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
    "                    float( len(set_true.union(set_pred)) )\n",
    "        #print('tmp_a: {0}'.format(tmp_a))\n",
    "        acc_list.append(tmp_a)\n",
    "    return np.mean(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f7a6254-334a-44ce-906c-bf4ea971a39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold =  0.5\n",
      "exact accuracy =  0.7760869565217391\n",
      "hamming loss =  0.22391304347826088\n",
      "label based accuracy =  0.7760869565217391\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "pred_test = predict.copy()\n",
    "pred_test[pred_test>=0.5] = 1\n",
    "pred_test[pred_test<0.5] = 0\n",
    "acc = accuracy_score(y_test.values,pred_test)\n",
    "haml_loss = hamming_loss(y_test.values,pred_test)\n",
    "label_acc = labelSetAccuracy(y_test.values,pred_test)\n",
    "print(\"threshold = \",thresholds)\n",
    "print(\"exact accuracy = \", acc)\n",
    "print(\"hamming loss = \",haml_loss)\n",
    "print(\"label based accuracy = \",label_acc)\n",
    "print(\"==============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7111dde4-07b7-40c8-b483-bd3c3218a2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      2167\n",
      "           1       0.73      0.73      0.73      1513\n",
      "\n",
      "    accuracy                           0.78      3680\n",
      "   macro avg       0.77      0.77      0.77      3680\n",
      "weighted avg       0.78      0.78      0.78      3680\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_test, pred_test, target_names=['0','1']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
